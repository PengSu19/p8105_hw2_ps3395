---
title: "p8105_hw2_ps3395.Rmd"
author: "PENG"
date: "2023-10-01"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE)
```

```{r libraries}
library(tidyverse)
library(readxl)
```
# Problem 1

### To merge these into a single data frame using year and month as keys across datasets

First clean the pols-month data, which with 822 observations and 9 variables. Separated the `mon` into `year`, `month`, and day and mapped month into strings. Then create a `president` variable taking values `gop` and `dem`, and remove `prez_dem`, `prez_gop`, and the `day` variable.
```{r}
#clean the data in pols-month.csv
pols_month = 
  read_csv("data/pols-month.csv") |>
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = T) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop"),
    month = month.name[month]) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

Secondly, for cleaning the snp.csv using a similar process to the above.
```{r}
snp = 
  read_csv("data/snp.csv",
           col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year>2023,year-100,year),
    month = month.name[month]) |>
  select(year, month, close) 
```

Third, tidy the unemployment data
```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )


unemployment = 
  read_csv("./data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Finally merge three datasets

```{r}
data_538 = 
  left_join(pols_month, snp) |>
  left_join(x = _, y = unemployment)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols_month` data has `r nrow(pols_month)` observations and `r ncol(pols_month)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols_month |> pull(year) |> min()` to `r pols_month |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`. \newline


# Problem 2

### Read and clean data from *"202207 Trash Wheel Collection Data.xlsx"*

```{r}
#Read and clean the Mr. Trash Wheel sheet
Mr_trash = 
  readxl::read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet = 1 ,range = "A2:N550") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(homes_powered = round ((weight_tons * 500) / 30, 0),
         trashID = "Mr")

#Use a similar process to import, clean, and organize the data for Professor Trash Wheel and Gwynnda
professor_trash = 
  readxl::read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet = 2 ,range = "A2:M97") |>
  janitor::clean_names() |>
  drop_na(dumpster)|>
  mutate(homes_powered = round ((weight_tons * 500) / 30, 0),
         trashID = "professor")

gwynnda_trash = 
  readxl::read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet = 4 ,range = "A2:K110") |>
  janitor::clean_names() |>
  drop_na(dumpster)|>
  mutate(homes_powered = round ((weight_tons * 500) / 30, 0),
         trashID = "gwynnda")

#finding same columns in three dataset
common_col = Reduce(intersect, list(names(Mr_trash), names(professor_trash), names(gwynnda_trash)))

#merge three dataset by same columns to a single tidy data
merge_trash = merge(Mr_trash, professor_trash, by= common_col,all = TRUE) 
merge_trash = merge(merge_trash, gwynnda_trash, by = common_col, all = TRUE)|>
  janitor::clean_names()
```

### Description 

Three datasets are involved in Problem 2, including *"Mr."*, *"Professor"* and *"Gwynnda"* Trash Wheel. Which containing `r nrow(Mr_trash)`, `r nrow(professor_trash)`, and `r nrow(gwynnda_trash)` observations respectively. Moreover, there are `r length(common_col)` common variables involved in these three datasets, such as

* `month`, `year` and `date` for recording the time.
* `weight_tons` and `volume_cubic_yards` represent the weights and volumes of the trash.
* `plastic_bottles`, `polystyrene` and `cigarette_butts` indicate trash amount in different types.
* `homes_powered` represents the average time that electricity converted from garbage can be used by a household.

Then merging these three datasets into one dataframe called *"merge_trash"*, which contains `r nrow(merge_trash)` observations and `r ncol(merge_trash)` variables. \newline

For available data, the total weight of trash collected by Professor Trash Wheel was `r sum(pull(professor_trash, weight_tons))` tons, and the total number of cigarette butts collected by Gwynnda in July of 2021 was `r format(sum(pull(filter(gwynnda_trash, month == "July" , year == 2021),cigarette_butts)), big.mark = ",")`.


# Problem 3

### Import, clean, and tidy the dataset of baseline demographics

```{r}
#import and clean the MCI baseline data
mci_baseline_na =
  read_csv("data/MCI_baseline.csv", skip = 1, na = ".") |>
  janitor::clean_names()|>
  mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4,
        1 ~ "carrier", 
        0 ~ "non_carrier"),
    apoe4 = as.factor(apoe4)
      )

#remove the NA
mci_baseline = mci_baseline_na |> drop_na(age_at_onset)
```

### Data import steps and features

In order to have a tidy MCI baseline data, firstly, read the raw data from relative paths with `.` in "Age at onset" transformed to `NA`, and applied `janitor::clean_names()` to rename the variables.  \newline

Secondly, `mutate` function was performed to label the sex and APOE4 carrier status for participants, for `sex`, "1" represented "Male" while "0" represented "Female", and for `apoe4`, "1" indicated "APOE4 carrier" while "0" indicated "APOE4 non_carrier". Then these two variables were transformed to factors.  \newline

In addition, as the study was focused on the MCI, participants who did not develop MCI do not meet the stated inclusion criteria and were removed by `drop_na` function. After all cleaning steps, only `r nrow(mci_baseline)` observations remained with `r ncol(mci_baseline)` variables.  \newline

In conclusion, `r nrow(mci_baseline_na)` participants were recruited, and only `r nrow(mci_baseline)` of these developed MCI. Furthermore, the average baseline age is `r round(mean(pull(mci_baseline,current_age)),2)` and there are `r round(nrow(filter(mci_baseline,sex == "female", apoe4 == "carrier"))/nrow(filter(mci_baseline,sex == "female")) *100,2)`% of women in the study carried APOE4.

### Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values

```{r}
#import and clean the MCI baseline data
mci_amyloid =
  read_csv("data/mci_amyloid.csv", skip = 1, na = "NA") |>
  janitor::clean_names() |>
  select(id = study_id, everything())
```

### Data import steps and features

Similarly, `read_csv` was applied to import *amyloid* data and `janitor::clean_names()` function was used to tidy the column names. In addition, in order to compare with baseline data, `study_id` in amyloid data was changed to `id`. For the dataset of longitudinally observed biomarker values, it contains `r nrow(mci_amyloid)` participants and `r ncol(mci_amyloid)` variables, which including `study_id` for each participants and `baseline` that represents the time (years) elapsed since the study baseline to the visit where biomarker Amyloid _ 42/40 ratio was measured.

### check difference
```{r}
# Check for participants appearing only in the baseline dataset
participants_only_in_baseline <- mci_baseline |>
  anti_join(mci_amyloid, by = "id")

# Check for participants appearing only in the amyloid dataset
participants_only_in_amyloid <- mci_amyloid |>
  anti_join(mci_baseline, by = "id")
```

### Comment 
Comparing cleaned baseline and amyloid datasets, there are `r nrow(participants_only_in_baseline)` participants appearing only in the baseline data, which are participants with ID "14", "49", "268", and `r nrow(participants_only_in_amyloid)` participants only in amyloid data.

### merge data
```{r}
# combined two dataset and only contains participants that appearing in both datasets.
merge_mci = 
  inner_join(mci_baseline, mci_amyloid,by = "id") 

#save data
write.csv(merge_mci,"data/merge_mci.csv" ,row.names = F)
```

### Description 
After combining baseline and amyloid data with participants that appearing in both datasets, the merging dataset *"merge_mci"* finally includes `r nrow(merge_mci)` observations with `r ncol(merge_mci)` variables that from two datasets.